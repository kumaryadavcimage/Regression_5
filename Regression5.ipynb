{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe62647d-b30d-4275-8eb9-e9d2cddf7047",
   "metadata": {},
   "source": [
    "#### Q1. What is Elastic Net Regression and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6784fec-0e4b-4c59-8ad1-1f7fb93adf1a",
   "metadata": {},
   "source": [
    "#### solve\n",
    "\n",
    "Elastic Net Regression is a regularization technique that combines features of both Ridge Regression and Lasso Regression. It is used in linear regression models when there is a high degree of multicollinearity among the predictor variables, which can lead to issues like overfitting. Elastic Net introduces both L1 (Lasso) and L2 (Ridge) regularization terms to the linear regression equation.\n",
    "\n",
    "Here's a brief overview of Ridge, Lasso, and Elastic Net Regression:\n",
    "\n",
    "a.Ridge Regression:\n",
    "\n",
    "Adds a penalty term to the linear regression equation that is proportional to the square of the magnitude of the coefficients.\n",
    "\n",
    "The objective function in Ridge Regression is to minimize the sum of squared errors plus the squared sum of the coefficients multiplied by a tuning parameter (alpha).\n",
    "\n",
    "b.Lasso Regression:\n",
    "\n",
    "Similar to Ridge, but it adds a penalty term proportional to the absolute value of the coefficients.\n",
    "\n",
    "The objective function in Lasso Regression is to minimize the sum of squared errors plus the absolute sum of the coefficients multiplied by a tuning parameter (alpha).\n",
    "\n",
    "c.Elastic Net Regression:\n",
    "\n",
    "Combines both L1 and L2 regularization terms.\n",
    "\n",
    "It has two tuning parameters: alpha (similar to Ridge and Lasso) and another parameter, denoted as \"l1_ratio,\" which determines the mix between L1 and L2 penalties.\n",
    "\n",
    "The elastic net penalty term is a linear combination of the L1 and L2 penalties.\n",
    "\n",
    "Key differences:\n",
    "\n",
    "Ridge Regression tends to shrink the coefficients towards zero, but it rarely sets them exactly to zero.\n",
    "\n",
    "Lasso Regression has a tendency to produce sparse models by setting some coefficients exactly to zero, effectively performing feature selection.\n",
    "\n",
    "Elastic Net Regression combines the advantages of both Ridge and Lasso by including both L1 and L2 penalties. It can handle situations where there are many correlated predictor variables and can perform feature selection while allowing for a grouping effect when predictors are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3888231a-6509-46f5-8893-ecdb0cf3cb3d",
   "metadata": {},
   "source": [
    "#### Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c68058-ebbc-4f96-8e47-a61cc858b166",
   "metadata": {},
   "source": [
    "#### solve\n",
    "\n",
    "Choosing the optimal values for the regularization parameters in Elastic Net Regression involves a process called hyperparameter tuning. The two main hyperparameters in Elastic Net are:\n",
    "\n",
    "a.Alpha (α): It controls the overall strength of the regularization. A higher value of α leads to stronger regularization.\n",
    "\n",
    "b.L1 Ratio (l1_ratiol1_ratio): It determines the mix between L1 and L2 penalties. A l1_ratiol1_ratio of 0 corresponds to Ridge Regression, a l1_ratiol1_ratio of 1 corresponds to Lasso Regression, and any value in between corresponds to a mix of both.\n",
    "\n",
    "Here are common approaches for choosing optimal values:\n",
    "\n",
    "Grid Search:\n",
    "\n",
    "Define a grid of values for α and l1_ratiol1_ratio.\n",
    "\n",
    "Train and evaluate the model for each combination of α and l1_ratiol1_ratio using cross-validation.\n",
    "\n",
    "Choose the combination of hyperparameters that gives the best performance (e.g., lowest mean squared error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84032fa2-fa20-4a50-a045-f719fe98c1b2",
   "metadata": {},
   "source": [
    "####\n",
    "Random Search:\n",
    "\n",
    "Similar to grid search, but instead of trying all combinations, randomly sample a subset of hyperparameter combinations.\n",
    "\n",
    "This can be more computationally efficient while still providing good results.\n",
    "\n",
    "Automated Techniques:\n",
    "\n",
    "Use automated techniques such as Bayesian optimization or genetic algorithms to search for optimal hyperparameters.\n",
    "\n",
    "These methods can be more efficient than grid or random search in high-dimensional spaces.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bdccc-8799-4567-b4ac-0a52a74fb2e7",
   "metadata": {},
   "source": [
    "#### Q3. What are the advantages and disadvantages of Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4329ed1a-900d-44ed-a276-e58ae4de0db0",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Advantages of Elastic Net Regression:\n",
    "\n",
    "a.Handles Multicollinearity:\n",
    "\n",
    "Elastic Net is effective when there are high correlations among predictor variables. The combination of L1 and L2 penalties allows it to select groups of correlated variables and prevent overfitting.\n",
    "\n",
    "b.Feature Selection:\n",
    "\n",
    "Like Lasso Regression, Elastic Net has the ability to perform feature selection by setting some coefficients to exactly zero. This can be valuable when dealing with high-dimensional datasets with many irrelevant features.\n",
    "\n",
    "c.Balancing Ridge and Lasso:\n",
    "\n",
    "By combining Ridge and Lasso penalties, Elastic Net can provide a balance between Ridge's ability to handle multicollinearity and Lasso's feature selection capability.\n",
    "\n",
    "d.Suitable for Large Datasets:\n",
    "\n",
    "Elastic Net can be computationally efficient and suitable for large datasets, especially when optimized solvers are used.\n",
    "\n",
    "e.Flexibility in Hyperparameter Tuning:\n",
    "\n",
    "Elastic Net has two hyperparameters (α and l1_ratl1_ratio), providing flexibility in controlling the overall strength of regularization and adjusting the mix between L1 and L2 penalties.\n",
    "\n",
    "Disadvantages of Elastic Net Regression:\n",
    "\n",
    "a.Interpretability:\n",
    "\n",
    "The presence of both L1 and L2 penalties can make the interpretation of the resulting model more complex compared to Ridge or Lasso Regression alone.\n",
    "\n",
    "b.Not Always Necessary:\n",
    "\n",
    "In cases where multicollinearity is not a significant issue or when the dataset is not high-dimensional, simpler regression techniques like ordinary least squares (OLS) regression might be sufficient and easier to interpret.\n",
    "\n",
    "c.Data Standardization Required:\n",
    "\n",
    "Elastic Net, like Ridge and Lasso, is sensitive to the scale of the predictor variables. It is often necessary to standardize or normalize the features before applying Elastic Net to ensure fair treatment of all variables.\n",
    "\n",
    "d.Hyperparameter Sensitivity:\n",
    "\n",
    "The performance of Elastic Net can be sensitive to the choice of hyperparameters (α andl1_ratiol1_ratio). Careful tuning is required to achieve optimal results, and the choice may depend on the specific characteristics of the dataset.\n",
    "\n",
    "e.Potential Over-regularization:\n",
    "\n",
    "If the regularization strength (α) is set too high, Elastic Net may lead to underfitting, and if set too low, it may lead to overfitting. Proper cross-validation is crucial to finding an appropriate balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd77cc-e4e2-400d-a473-3b5357283c57",
   "metadata": {},
   "source": [
    "#### Q4. What are some common use cases for Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c705c-28ba-4f72-90b2-e11445a9ba52",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Elastic Net Regression is a versatile regularization technique that can be applied in various scenarios, particularly when dealing with linear regression problems. Here are some common use cases for Elastic Net Regression:\n",
    "\n",
    "a.High-Dimensional Datasets:\n",
    "\n",
    "Elastic Net is well-suited for datasets with a large number of predictor variables (features), especially when many of these variables are potentially irrelevant or highly correlated. It helps prevent overfitting and can perform feature selection.\n",
    "\n",
    "b.Multicollinearity:\n",
    "\n",
    "When there is multicollinearity among predictor variables (high correlation between features), Elastic Net is beneficial. It can handle situations where the traditional least squares regression might struggle due to instability in coefficient estimates.\n",
    "\n",
    "c.Genomics and Bioinformatics:\n",
    "\n",
    "In genomics and bioinformatics, datasets often have a large number of variables with potential collinearity. Elastic Net can be used for predicting biological outcomes or identifying important genetic markers while handling the inherent complexity of the data.\n",
    "\n",
    "d.Finance:\n",
    "\n",
    "Financial datasets often contain numerous financial indicators and economic variables that may be correlated. Elastic Net can help build more robust models for predicting stock prices, risk assessments, or credit scoring by handling multicollinearity and providing feature selection.\n",
    "\n",
    "e.Marketing and Customer Analytics:\n",
    "\n",
    "In marketing analytics, companies may have a multitude of features related to customer behavior, demographics, and preferences. Elastic Net can be applied to build predictive models for customer churn, customer lifetime value, or purchase behavior.\n",
    "\n",
    "f.Environmental Science:\n",
    "\n",
    "Environmental datasets often involve a large number of variables, and some of these variables may be correlated due to geographical or climatic factors. Elastic Net can be used to model and predict environmental outcomes, such as air quality or ecosystem health.\n",
    "\n",
    "g.Text and Natural Language Processing:\n",
    "\n",
    "In text analysis and natural language processing, feature spaces can be high-dimensional, especially when using techniques like bag-of-words or TF-IDF. Elastic Net can help in building more robust models for sentiment analysis, text classification, or topic modeling.\n",
    "\n",
    "h.Medical Research:\n",
    "\n",
    "In medical research, datasets may have a large number of biological or clinical variables. Elastic Net can be applied to model relationships between these variables and predict outcomes in areas such as disease diagnosis or prognosis.\n",
    "\n",
    "i.Economics and Econometrics:\n",
    "\n",
    "Economic datasets often involve various economic indicators and variables that may exhibit multicollinearity. Elastic Net can be employed to build regression models for forecasting economic indicators or studying the impact of different factors.\n",
    "\n",
    "j.Machine Learning Pipelines:\n",
    "\n",
    "In machine learning pipelines, Elastic Net can be used as a regularized regression model within a broader framework. It can be part of ensemble methods, stacked models, or combined with other algorithms to improve overall predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45b5f76-dce5-4979-b8d4-da1771e30310",
   "metadata": {},
   "source": [
    "#### Q5. How do you interpret the coefficients in Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd21f3-4b9b-41c0-94e8-640edce11c97",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Interpreting coefficients in Elastic Net Regression involves understanding the impact of each predictor variable on the target variable while considering the regularization effects introduced by the combination of L1 and L2 penalties. The interpretation is somewhat more complex compared to standard linear regression, but it follows similar principles.\n",
    "\n",
    "In Elastic Net, the objective function includes both L1 and L2 penalty terms, and the elastic net penalty term is given by:\n",
    "\n",
    "Elastic Net Penalty=(l1_ratio∑=1∣∣+12(1−l1_ratio)∑=12)Elastic Net Penalty=α(l1_ratio∑ i=1p∣β i∣+ 21(1−l1_ratio)∑ i=1pβ i2)\n",
    "\n",
    "Here:\n",
    "\n",
    "α is the regularization parameter that controls the overall strength of regularization.\n",
    "\n",
    "l1_ratio\n",
    "\n",
    "l1_ratio determines the mix between L1 and L2 penalties.β irepresents the regression coefficients for each predictor variable.\n",
    "\n",
    "The interpretation of coefficients involves considering the following:\n",
    "\n",
    "a.Magnitude of Coefficients:\n",
    "\n",
    "The magnitude of each coefficient (β i) indicates the strength of the relationship between the corresponding predictor variable and the target variable. Larger coefficients suggest a stronger impact.\n",
    "\n",
    "b.Sign of Coefficients:\n",
    "\n",
    "The sign of each coefficient indicates the direction of the relationship. A positive sign means that an increase in the predictor variable is associated with an increase in the target variable, while a negative sign indicates a decrease.\n",
    "\n",
    "c.Shrinkage and Sparsity:\n",
    "\n",
    "Elastic Net introduces shrinkage, which means that some coefficients may be pushed towards zero, especially if the L1 penalty is dominant. Coefficients that are exactly zero imply that the corresponding features have been excluded from the model, providing a form of automatic feature selection.\n",
    "\n",
    "d.Comparison with Ordinary Least Squares (OLS):\n",
    "\n",
    "If you have a purely linear model with no regularization (=0α=0), the coefficients in Elastic Net should converge towards the OLS estimates.\n",
    "\n",
    "e.Interaction between Features:\n",
    "\n",
    "The impact of a specific predictor may be influenced by the presence of other correlated predictors. Elastic Net's ability to handle multicollinearity means that coefficients are adjusted considering the joint effects of correlated features.\n",
    "\n",
    "It's important to note that the interpretation becomes more challenging as the regularization strength (α) increases, and the coefficients are more likely to be shrunken towards zero. The choice of α andl1_ratiol1_ratio influences the sparsity and shrinkage effects. Cross-validation is often used to find optimal hyperparameters that balance model complexity and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca487ed-8a42-4259-9cdb-c029d35dcba8",
   "metadata": {},
   "source": [
    "#### Q6. How do you handle missing values when using Elastic Net Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4539cb0e-9dde-49bf-8f50-d6f924430864",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Handling missing values is an important aspect of building any regression model, including Elastic Net Regression. The presence of missing values in the dataset can impact the model's performance and interpretation. Here are several strategies you can consider when dealing with missing values in the context of Elastic Net Regression:\n",
    "\n",
    "a.Data Imputation:\n",
    "\n",
    "Imputation involves filling in missing values with estimated or imputed values. Common imputation methods include mean imputation, median imputation, or imputation using more advanced techniques such as k-nearest neighbors (KNN) or regression imputation.\n",
    "\n",
    "Care should be taken to impute values separately for the training and testing datasets to avoid data leakage.\n",
    "\n",
    "b.Feature Engineering:\n",
    "\n",
    "If the missing values are informative or provide meaningful information, consider creating a new binary feature indicating the presence or absence of missing values for a particular variable. This way, the model can learn from the missingness pattern.\n",
    "\n",
    "c.Removing Missing Values:\n",
    "\n",
    "If the proportion of missing values for a particular variable is small and random, you might choose to remove the corresponding observations with missing values. However, this approach should be used cautiously to avoid significant data loss.\n",
    "\n",
    "d.Use of Missing Indicators:\n",
    "\n",
    "Instead of imputing missing values, you can create binary indicator variables for each predictor that has missing values. This way, the model can explicitly account for the absence of information for certain observations.\n",
    "\n",
    "e.Advanced Imputation Techniques:\n",
    "\n",
    "Consider using more advanced imputation techniques, such as multiple imputation, which generates multiple complete datasets with imputed values and combines the results to provide more robust estimates.\n",
    "\n",
    "Here is an example using Python with the scikit-learn library to handle missing values and perform Elastic Net Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aa1a99-c678-47e0-9e8f-e53be4f95cb6",
   "metadata": {},
   "source": [
    "#### Q7. How do you use Elastic Net Regression for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ef0b10-2f0a-4233-b232-74f2bcaf6caa",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Elastic Net Regression is a powerful tool for feature selection due to its ability to introduce sparsity in the model coefficients, effectively setting some coefficients to zero. Here's how you can use Elastic Net Regression for feature selection:\n",
    "\n",
    "Regularization Strength (α):\n",
    "\n",
    "The regularization strength parameter (α) controls the overall amount of regularization applied to the model. Higher values of α lead to stronger regularization, potentially resulting in more coefficients being set to zero. Therefore, selecting an appropriate value of α is crucial for effective feature selection.\n",
    "\n",
    "L1 Ratio (l1_ratio l1_ratio):\n",
    "\n",
    "The L1 ratio parameter (l1_ratio l1_ratio) determines the mix between L1 (Lasso) and L2 (Ridge) penalties in the elastic net penalty term. When l1_ratio=1l1_ratio=1, it is equivalent to Lasso Regression, favoring sparsity and encouraging more coefficients to be exactly zero. Values closer to 0 or 1 provide a stronger preference for feature selection.\n",
    "\n",
    "Cross-Validation:\n",
    "\n",
    "Use cross-validation to find the optimal values of α and l1_ratio l1_ratio. Scikit-learn provides tools like ElasticNetCV for cross-validated hyperparameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f496f-a7c1-402d-83ff-095e1167bd97",
   "metadata": {},
   "source": [
    "#### Evaluate and Refine:\n",
    "Evaluate the model's performance on a validation set and refine the feature selection if necessary. Adjust the hyperparameters or consider additional pre-processing steps based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe082e-806c-4cae-a2d6-e3ca0da6c02c",
   "metadata": {},
   "source": [
    "#### Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0b508-cd5e-4ca5-9d65-6e478a0b3418",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Pickle is a Python module that allows you to serialize and deserialize objects, making it easy to save trained models and reload them later. Here's how you can pickle and unpickle a trained Elastic Net Regression model using the pickle module:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42bfdb3-8329-4b74-bc5e-1dfad08df130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 61.124696161855184\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate some example data\n",
    "X, y = make_regression(n_samples=100, n_features=5, noise=0.1, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an Elastic Net model\n",
    "elastic_net_model = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = elastic_net_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Pickle the trained model\n",
    "with open('elastic_net_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(elastic_net_model, model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48a3d0-c83b-40f4-9ed5-4594bcc3d475",
   "metadata": {},
   "source": [
    "#### \n",
    "In this example, the pickle.dump() function is used to save the trained Elastic Net model to a file named 'elastic_net_model.pkl'. The 'wb' argument specifies that the file should be opened in binary write mode.\n",
    "\n",
    "To unpickle and load the model later, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d61a2b-2d91-4299-8d39-408d7d887afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (Loaded Model): 61.124696161855184\n"
     ]
    }
   ],
   "source": [
    "# Unpickle the trained model\n",
    "with open('elastic_net_model.pkl', 'rb') as model_file:\n",
    "    loaded_elastic_net_model = pickle.load(model_file)\n",
    "\n",
    "# Now you can use the loaded model for predictions\n",
    "loaded_y_pred = loaded_elastic_net_model.predict(X_test)\n",
    "loaded_mse = mean_squared_error(y_test, loaded_y_pred)\n",
    "print(f'Mean Squared Error (Loaded Model): {loaded_mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a68abd-1dca-4660-b137-57c27eae0fa1",
   "metadata": {},
   "source": [
    "#### This code opens the file containing the pickled model ('elastic_net_model.pkl') in binary read mode ('rb') and uses pickle.load() to load the model into a new variable (loaded_elastic_net_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad28b55-8dcd-4e47-82f0-fe79b191e27a",
   "metadata": {},
   "source": [
    "#### Q9. What is the purpose of pickling a model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b002c-3f91-408a-991d-df59e0f9554b",
   "metadata": {},
   "source": [
    "#### solve\n",
    "Pickling a model in machine learning refers to the process of serializing the trained model object into a binary format, allowing it to be saved to a file. The primary purpose of pickling a model is to persistently store the model's state, including its architecture, learned parameters, and any pre-processing steps, so that it can be later reloaded and used for predictions without the need to retrain the model.\n",
    "\n",
    "Here are some key purposes and benefits of pickling a model in machine learning:\n",
    "\n",
    "a.Model Deployment:\n",
    "\n",
    "Pickling is crucial for deploying machine learning models in production environments. Once a model is trained and validated, it can be pickled and then deployed in a production system to make real-time predictions without the need to retrain the model on each prediction.\n",
    "\n",
    "b.Scalability:\n",
    "\n",
    "For applications that require scalability, pickling allows trained models to be easily distributed across multiple servers or containers. Each instance can load the pickled model, eliminating the need to retrain the model on each server.\n",
    "\n",
    "c.Data Science Pipelines:\n",
    "\n",
    "Pickling is useful for saving not only the trained model but also the entire data processing pipeline, including feature scaling, encoding, and any other pre-processing steps. This ensures consistency when transforming new data for predictions.\n",
    "\n",
    "d.Reproducibility:\n",
    "\n",
    "Pickling facilitates reproducibility by saving the exact state of the model at the time of training. This is important for research, collaboration, and auditing purposes, as others can load the pickled model and reproduce the same predictions.\n",
    "\n",
    "e.Saving Training Time:\n",
    "\n",
    "Training machine learning models can be computationally expensive and time-consuming. By pickling the trained model, you can save the state of the model and avoid the need to retrain it from scratch, especially when dealing with large datasets.\n",
    "\n",
    "f.Interoperability:\n",
    "\n",
    "Pickling allows trained models to be easily shared between different Python environments and platforms. This interoperability is important when collaborating with colleagues, sharing models across teams, or integrating models into different applications.\n",
    "\n",
    "Training Phase:\n",
    "\n",
    "Train and validate your machine learning model on a dataset.\n",
    "\n",
    "Once satisfied with the model's performance, pickle the trained model using the pickle module or alternative serialization libraries (e.g., joblib).\n",
    "\n",
    "Deployment or Inference Phase:\n",
    "\n",
    "3. In a different environment (e.g., a production server), load the pickled model using the same or compatible Python environment.\n",
    "\n",
    "Use the loaded model to make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a572bc3-e58f-40c8-8e2f-cf21947c5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
